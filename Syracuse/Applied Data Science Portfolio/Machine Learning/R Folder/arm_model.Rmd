---
title: "Associatoin Rule Mining"
author: "Daniel Caley"
date: "9/17/2021"
output: pdf_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(arules)
library(arulesViz)
library(dplyr)
library(ggplot2)
library(data.table)




```


```{r message=FALSE, warning=FALSE}

MyNetflix <- read_csv("data/netflixData.csv")
CleanFlix <- MyNetflix %>% filter(
                                  `Production Country` %like% "United States" &
                                  `Content Type` == "Movie" &
                                  Director != "" &
                                  Cast != ""
                                  ) %>% 
                           mutate(
                                  `Imdb Score` = as.numeric(str_remove(`Imdb Score`,"/10")),
                                  Duration = as.numeric((str_remove(Duration, " min"))),
                                  Duration_bins = as.ordered(ceiling(Duration / 30) * 30),
                                  internation_flag = str_count(`Production Country`) != 13
                           ) %>% dplyr::select(-`Date Added`)
 

## Cleaning the Ratings
CleanFlix <- CleanFlix %>% dplyr::mutate(
                                  Rating = str_remove(Rating,"TV-"),
                                  Rating = case_when(Rating == "Y" ~ "G",
                                                     Rating == "Y7" ~ "PG",
                                                     Rating == "14" ~ "PG-13",
                                                     Rating == "MA" ~ "R",
                                                     TRUE ~ Rating)
                                  ) %>% filter(!is.na(`Imdb Score`))

```



```{r echo=FALSE}

FlixGenre <- CleanFlix %>% dplyr::select(Genres)

FlixGenreRows <- FlixGenre %>% mutate(Genres2 = strsplit(Genres,", ")) %>% unnest(Genres2)

FlixGenre <- separate(FlixGenre, "Genres", paste("Genres", 1:3, sep = "_"), sep = ",", extra = "drop") %>% 
                        mutate(across(contains("Genres"), ~ as.factor(.)))

write_csv(FlixGenre, "FlixGenre.csv")

GenreTransactions <- read.transactions("FlixGenre.csv", format = "basket", sep=",", skip = 1)


inspect(GenreTransactions[1:20])

# Create an item frequency plot for the top 20 items
itemFrequencyPlot(GenreTransactions,topN=20,type="absolute")

```





We are now ready to mine some rules!
We will look at *support* and *confidence*.
-   *support* is an indication of how frequently an items appear in the data
-   *confidence* indicates the number of times the if-then statements are found true.

-   We set the minimum support to 0.001 in order to pull as many items into our dataset, but not all items as we don't want transactions that didn't have as many associations.
-   We set the minimum confidence of 0.8 to only bring in items that have a confidence over 0.8.

We can get summary info. about the rules that give us some interesting information such as:

-   The number of rules generated: 8
-   The distribution of rules by length: Most rules are 3 items long
-   The summary of quality measures: interesting to see ranges of support, lift, and confidence.
-   The information on the data mined: total data mined, and minimum parameters.

```{r echo=FALSE}

# generate rules
# Dan why did you set the support, confidence, and maxlen as these values.
rules <- apriori(GenreTransactions,  parameter = list(supp = 0.001, conf = 0.8))

# Rounding rules to 2 digits
options(digits=2)

# get summary info about all rules
summary(rules)




```



## Exploring Metrics to Evaluate - Confidence

The chart below shows a general sense of what the rules look like when we sort by confident.


```{r echo=FALSE}

# sort the rules to view most relevant first (confidence)
rules <- sort(rules, by="confidence", decreasing=TRUE)
inspect(rules)


```

# Plotting the Association Rule
```{r echo=FALSE}

plot(rules,method="graph",shading=NA)

```






